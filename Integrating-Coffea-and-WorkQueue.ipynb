{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Integrating Coffea and Work Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is Coffea?\n",
    "Coffea is a prototype package for pulling together all the typical needs of a high-energy collider physics (HEP) experiment analysis using the scientific python ecosystem.\n",
    "\n",
    "https://coffeateam.github.io/coffea/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is Work Queue?\n",
    "Work Queue is a framework for building large master-worker applications that span thousands of machines drawn from clusters, clouds, and grids.\n",
    "\n",
    "https://cctools.readthedocs.io/en/latest/work_queue/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Work Queue?\n",
    "\n",
    "- **Elastic:** Workers can be added and removed during runtime, and the master automatically uses the workers available.\n",
    "- **Robust:** Tasks running on workers that fail are automatically detected and handled elsewhere.\n",
    "- **Efficient:** Files may be cached at the workers, which reduces transfer times and network utilization.\n",
    "- **Resource Management:**  Resources such as core, memory, and disk are measured automatically, so as to run as many tasks as possible given the available workers.\n",
    "- **Agnostic:** Masters can be written in Python, Perl, or C. It is able to work with existing cluster and cloud systems: HTCondor, PBS, TORQUE, Slurm, EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Setting up the conda environment for the first time\n",
    "\n",
    "In a separate terminal on the same machine as this notebook, run the following commands to set up a conda environment for the first time.\n",
    "\n",
    "Once the installation is complete, change the kernel of your Jupyter Notebook to workqueue-coffea.\n",
    "\n",
    "```\n",
    "$ conda create --name workqueue-coffea python=3.8 six dill\n",
    "$ conda activate workqueue-coffea\n",
    "$ conda install -c conda-forge xrootd ndcctools anaconda ipykernel\n",
    "$ pip install coffea\n",
    "$ python -m ipykernel install --user --name=workqueue-coffea\n",
    "$ conda activate base\n",
    "$ pip install conda-pack\n",
    "$ python -c 'import conda_pack; conda_pack.pack(name=\"workqueue-coffea\", output=\"workqueue-coffea.tar.gz\")'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on distributed systems \n",
    "Whenever we want to run a task on a remote worker, we have to send all files/programs that the task will use because we cannot expect that the machine the task runs on will have everything we need installed. We must create a file defining the conda environment we wish to run our tasks on and send it to the workers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries for python\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from coffea.processor import iterative_executor, work_queue_executor\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FancyDimuonProcessor\n",
    "It can be found here: \n",
    "https://coffeateam.github.io/coffea/notebooks/processor.html#Getting-fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class FancyDimuonProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        mass_axis = hist.Bin(\"mass\", r\"$m_{\\mu\\mu}$ [GeV]\", 600, 0.25, 300)\n",
    "        pt_axis = hist.Bin(\"pt\", r\"$p_{T,\\mu}$ [GeV]\", 3000, 0.25, 300)\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'mass': hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            'mass_near': hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            'mass_far': hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            'pt_lead': hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            'pt_trail': hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        output = self.accumulator.identity()\n",
    "\n",
    "        dataset = df['dataset']\n",
    "        muons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nMuon'],\n",
    "            pt=df['Muon_pt'],\n",
    "            eta=df['Muon_eta'],\n",
    "            phi=df['Muon_phi'],\n",
    "            mass=df['Muon_mass'],\n",
    "            charge=df['Muon_charge'],\n",
    "            softId=df['Muon_softId'],\n",
    "            tightId=df['Muon_tightId']\n",
    "            )\n",
    "\n",
    "        output['cutflow']['all events'] += muons.size\n",
    "\n",
    "        soft_id = (muons.softId > 0)\n",
    "        muons = muons[soft_id]\n",
    "        output['cutflow']['soft id'] += soft_id.any().sum()\n",
    "\n",
    "        twomuons = (muons.counts >= 2)\n",
    "        output['cutflow']['two muons'] += twomuons.sum()\n",
    "\n",
    "        dimuons = muons[twomuons].distincts()\n",
    "\n",
    "        twodimuons = (dimuons.counts >= 2)\n",
    "        output['cutflow']['>= two dimuons'] += twodimuons.sum()\n",
    "        dimuons = dimuons[twodimuons]\n",
    "\n",
    "        opposite_charge = (dimuons.i0['charge'] * dimuons.i1['charge'] == -1)\n",
    "\n",
    "        dimuons = dimuons[opposite_charge]\n",
    "        output['cutflow']['opposite charge'] += opposite_charge.any().sum()\n",
    "\n",
    "        mass_20GeV = (dimuons.mass > 35)\n",
    "        dimuons = dimuons[mass_20GeV]\n",
    "\n",
    "        exactlytwodimuons = (dimuons.counts == 2)\n",
    "        output['cutflow']['== two dimuons'] += exactlytwodimuons.sum()\n",
    "        dimuons = dimuons[exactlytwodimuons].compact()\n",
    "\n",
    "        leading_mu = (dimuons.i0.pt.content > dimuons.i1.pt.content)\n",
    "        pt_lead = JaggedArray.fromoffsets(dimuons.offsets, np.where(leading_mu,\n",
    "                                            dimuons.i0.pt.content, dimuons.i1.pt.content))\n",
    "        pt_trail = JaggedArray.fromoffsets(dimuons.offsets, np.where(~leading_mu,\n",
    "                                            dimuons.i0.pt.content, dimuons.i1.pt.content))\n",
    "\n",
    "        near_z = np.abs(dimuons.mass - 91.118).argmin()\n",
    "        far_z = np.abs(dimuons.mass - 91.118).argmax()\n",
    "\n",
    "        output['mass'].fill(dataset=dataset,\n",
    "                            mass=dimuons.p4.sum().mass)\n",
    "        output['mass_near'].fill(dataset=dataset,\n",
    "                                 mass=dimuons.mass[near_z].flatten())\n",
    "        output['mass_far'].fill(dataset=dataset,\n",
    "                                mass=dimuons.mass[far_z].flatten())\n",
    "        output['pt_lead'].fill(dataset=dataset,\n",
    "                               pt=pt_lead.flatten())\n",
    "        output['pt_trail'].fill(dataset=dataset,\n",
    "                                pt=pt_trail.flatten())\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the variables we need\n",
    "\n",
    "First, we set the chunk size. The chunk size tells us how many entries from the file to process at once in a single \"task\". A larger chunksize allows for less and larger \"tasks\". The chunksize we are using results in 60 tasks.  \n",
    "\n",
    "Next, we set the fileset which we want to process. Files can be found in the Coffea example here: https://coffeateam.github.io/coffea/notebooks/processor.html#Getting-fancy\n",
    "\n",
    "Lastly, we set the arguments we want to pass to our executor. Most of these are unique to the work_queue_executor. \n",
    "- **cores/disk/memory:** We have to tell the Work Queue master how much of each resource is going to be used by each task (this is not necessary but greatly improves performance when using accurate values).\n",
    "- **resource-monitor:** A tool that monitors the computational resources used by the process created by the command given as an argument, and all its descendants. https://cctools.readthedocs.io/en/latest/resource_monitor/.\n",
    "- **port:** The port on which the master will listen for tasks to be submitted by the application. 0 specifies any available port.\n",
    "- **environment-file:** The tar-ed conda environment that will be sent to each worker in order to be able to run Coffea.\n",
    "- **master-name:** This is necessary to be able to run Work Queue. The workers use this master-name to connect to the master."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "chunk_size = 30000 #default is 100000\n",
    "\n",
    "fileset = { #files found on Coffea site in \"Fancy\" processor example\n",
    "    #'DoubleMuon': [\n",
    "    #    'root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/Run2012B_DoubleMuParked.root',\n",
    "    #    'root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/Run2012C_DoubleMuParked.root',\n",
    "    #],\n",
    "    'ZZ to 4mu': [\n",
    "        'root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/ZZTo4mu.root'\n",
    "    ]\n",
    "}\n",
    "\n",
    "executor_args = {'debug': True,\n",
    "            'flatten': True, #used for all executors\n",
    "            'compression': 0, #used for all executors\n",
    "            'cores': 2, \n",
    "            'disk': 1000, #MB\n",
    "            'memory': 2000, #MB\n",
    "            'resource-monitor': True,\n",
    "            'port': 0,\n",
    "            'environment-file': 'workqueue-coffea.tar.gz', #the conda environment we created and packed at the beginning\n",
    "            'master-name': 'workqueue-coffea',\n",
    "            'print-stdout': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run Coffea - Iterative Executor\n",
    "\n",
    "Here, we run the Coffea analysis tool using the iterative_executor which will split the data into various tasks and run them sequentially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51ea15bbfc044bfad97ee5a67e58cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Preprocessing', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d868160ffe534a4c970ff563713ba7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Processing', max=50.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "iterative_start = time()\n",
    "\n",
    "#run using iterative executor\n",
    "output_iterative = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=FancyDimuonProcessor(),\n",
    "                                  executor=iterative_executor,\n",
    "                                  executor_args={'flatten': True},\n",
    "                                  chunksize=chunk_size\n",
    "                                 )\n",
    "\n",
    "iterative_time = time() - iterative_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Start Workers\n",
    "\n",
    "Before we run Coffea with Work Queue, we need to request some workers. \n",
    "\n",
    "To start a single worker, open a terminal on the same machine and within the same environment as this notebook and run the following command: \n",
    "\n",
    "`$ work_queue_worker -M workqueue-coffea`\n",
    "\n",
    "To start 10 workers with other batch systems, use any one of the following commands:\n",
    "- **Condor:** `$ condor_submit_workers -M workqueue-coffea --cores 4 --memory 4000 --disk 2000 10`\n",
    "- **SGE:** `$ sge_submit_workers -M workqueue-coffea --cores 4 --memory 4000 --disk 2000 10`\n",
    "- **PBS:** `$ pbs_submit_workers -M workqueue-coffea --cores 4 --memory 4000 --disk 2000 10`\n",
    "- **Torque:** `$ torque_submit_workers -M workqueue-coffea --cores 4 --memory 4000 --disk 2000 10`\n",
    "- **Slurm:** `$ slurm_submit_workers -M workqueue-coffea --cores 4 --memory 4000 --disk 2000 10`\n",
    "- **EC2:** `$ ec2_submit_workers -M workqueue-coffea --cores 4 --memory 4000 --disk 2000 10`\n",
    "\n",
    "Further information can be found here: https://cctools.readthedocs.io/en/latest/work_queue/#running-a-work-queue-application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating worker submit scripts in /tmp/ccarball-workers...\n",
      "Submitting job(s)..........\n",
      "10 job(s) submitted to cluster 439133.\n"
     ]
    }
   ],
   "source": [
    "!condor_submit_workers -M workqueue-coffea --cores 4 --memory 4000 --disk 2000 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Coffea - Work Queue Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for work queue workers on port 1025...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5df31512674b0c91680b1e682c0d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Processing', max=50.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted task (id #1): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_0.p output_0.p\n",
      "Submitted task (id #2): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_1.p output_1.p\n",
      "Submitted task (id #3): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_2.p output_2.p\n",
      "Submitted task (id #4): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_3.p output_3.p\n",
      "Submitted task (id #5): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_4.p output_4.p\n",
      "Submitted task (id #6): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_5.p output_5.p\n",
      "Submitted task (id #7): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_6.p output_6.p\n",
      "Submitted task (id #8): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_7.p output_7.p\n",
      "Submitted task (id #9): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_8.p output_8.p\n",
      "Submitted task (id #10): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_9.p output_9.p\n",
      "Submitted task (id #11): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_10.p output_10.p\n",
      "Submitted task (id #12): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_11.p output_11.p\n",
      "Submitted task (id #13): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_12.p output_12.p\n",
      "Submitted task (id #14): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_13.p output_13.p\n",
      "Submitted task (id #15): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_14.p output_14.p\n",
      "Submitted task (id #16): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_15.p output_15.p\n",
      "Submitted task (id #17): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_16.p output_16.p\n",
      "Submitted task (id #18): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_17.p output_17.p\n",
      "Submitted task (id #19): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_18.p output_18.p\n",
      "Submitted task (id #20): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_19.p output_19.p\n",
      "Submitted task (id #21): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_20.p output_20.p\n",
      "Submitted task (id #22): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_21.p output_21.p\n",
      "Submitted task (id #23): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_22.p output_22.p\n",
      "Submitted task (id #24): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_23.p output_23.p\n",
      "Submitted task (id #25): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_24.p output_24.p\n",
      "Submitted task (id #26): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_25.p output_25.p\n",
      "Submitted task (id #27): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_26.p output_26.p\n",
      "Submitted task (id #28): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_27.p output_27.p\n",
      "Submitted task (id #29): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_28.p output_28.p\n",
      "Submitted task (id #30): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_29.p output_29.p\n",
      "Submitted task (id #31): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_30.p output_30.p\n",
      "Submitted task (id #32): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_31.p output_31.p\n",
      "Submitted task (id #33): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_32.p output_32.p\n",
      "Submitted task (id #34): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_33.p output_33.p\n",
      "Submitted task (id #35): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_34.p output_34.p\n",
      "Submitted task (id #36): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_35.p output_35.p\n",
      "Submitted task (id #37): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_36.p output_36.p\n",
      "Submitted task (id #38): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_37.p output_37.p\n",
      "Submitted task (id #39): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_38.p output_38.p\n",
      "Submitted task (id #40): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_39.p output_39.p\n",
      "Submitted task (id #41): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_40.p output_40.p\n",
      "Submitted task (id #42): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_41.p output_41.p\n",
      "Submitted task (id #43): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_42.p output_42.p\n",
      "Submitted task (id #44): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_43.p output_43.p\n",
      "Submitted task (id #45): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_44.p output_44.p\n",
      "Submitted task (id #46): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_45.p output_45.p\n",
      "Submitted task (id #47): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_46.p output_46.p\n",
      "Submitted task (id #48): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_47.p output_47.p\n",
      "Submitted task (id #49): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_48.p output_48.p\n",
      "Submitted task (id #50): ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_49.p output_49.p\n",
      "\n",
      "Waiting for tasks to complete...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task (id #1) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_0.p output_0.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 115 MB, disk 990 MB, runtime 36.103177\n",
      "Task (id #2) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_1.p output_1.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 107 MB, disk 990 MB, runtime 42.898914\n",
      "Task (id #3) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_2.p output_2.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 105 MB, disk 990 MB, runtime 38.302427\n",
      "Task (id #5) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_4.p output_4.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 103 MB, disk 990 MB, runtime 8.078014\n",
      "Task (id #4) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_3.p output_3.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 105 MB, disk 990 MB, runtime 38.798253\n",
      "Task (id #7) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_6.p output_6.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 105 MB, disk 990 MB, runtime 8.468131\n",
      "Task (id #8) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_7.p output_7.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 112 MB, disk 990 MB, runtime 7.688366\n",
      "Task (id #9) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_8.p output_8.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 122 MB, disk 990 MB, runtime 10.297986\n",
      "Task (id #6) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_5.p output_5.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 110 MB, disk 990 MB, runtime 49.797327\n",
      "Task (id #12) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_11.p output_11.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 9.881378\n",
      "Task (id #13) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_12.p output_12.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 109 MB, disk 990 MB, runtime 8.629075\n",
      "Task (id #14) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_13.p output_13.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 110 MB, disk 990 MB, runtime 9.387938\n",
      "Task (id #15) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_14.p output_14.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 110 MB, disk 990 MB, runtime 10.001097\n",
      "Task (id #10) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_9.p output_9.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 109 MB, disk 990 MB, runtime 46.978265\n",
      "Task (id #16) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_15.p output_15.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 106 MB, disk 990 MB, runtime 36.999277\n",
      "Task (id #17) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_16.p output_16.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 121 MB, disk 990 MB, runtime 13.723109\n",
      "Task (id #18) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_17.p output_17.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 130 MB, disk 990 MB, runtime 8.529086\n",
      "Task (id #19) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_18.p output_18.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 110 MB, disk 990 MB, runtime 10.341474\n",
      "Task (id #20) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_19.p output_19.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 103 MB, disk 990 MB, runtime 11.190709\n",
      "Task (id #21) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_20.p output_20.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 106 MB, disk 990 MB, runtime 10.297791\n",
      "Task (id #11) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_10.p output_10.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 170 MB, disk 990 MB, runtime 55.939992\n",
      "Task (id #24) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_23.p output_23.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 103 MB, disk 990 MB, runtime 8.842435\n",
      "Task (id #26) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_25.p output_25.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 108 MB, disk 990 MB, runtime 9.672089\n",
      "Task (id #27) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_26.p output_26.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 9.970454\n",
      "Task (id #29) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_28.p output_28.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 10.11457\n",
      "Task (id #30) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_29.p output_29.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 9.990588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task (id #28) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_27.p output_27.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 122 MB, disk 990 MB, runtime 10.573684\n",
      "Task (id #25) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_24.p output_24.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 129 MB, disk 990 MB, runtime 11.925775\n",
      "Task (id #22) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_21.p output_21.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 109 MB, disk 990 MB, runtime 44.888463\n",
      "Task (id #32) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_31.p output_31.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 109 MB, disk 990 MB, runtime 6.81211\n",
      "Task (id #31) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_30.p output_30.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 122 MB, disk 990 MB, runtime 12.834136\n",
      "Task (id #33) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_32.p output_32.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 132 MB, disk 990 MB, runtime 11.693233\n",
      "Task (id #34) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_33.p output_33.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 10.07614\n",
      "Task (id #35) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_34.p output_34.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 10.248443\n",
      "Task (id #36) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_35.p output_35.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 9.882639\n",
      "Task (id #37) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_36.p output_36.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 120 MB, disk 990 MB, runtime 11.253399\n",
      "Task (id #38) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_37.p output_37.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 105 MB, disk 990 MB, runtime 9.911952\n",
      "Task (id #39) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_38.p output_38.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 111 MB, disk 990 MB, runtime 11.123925\n",
      "Task (id #40) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_39.p output_39.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 10.732761\n",
      "Task (id #41) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_40.p output_40.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 108 MB, disk 990 MB, runtime 10.225192\n",
      "Task (id #50) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_49.p output_49.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 110 MB, disk 990 MB, runtime 6.937712\n",
      "Task (id #49) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_48.p output_48.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 8.431419\n",
      "Task (id #44) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_43.p output_43.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 111 MB, disk 990 MB, runtime 8.611636\n",
      "Task (id #47) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_46.p output_46.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 108 MB, disk 990 MB, runtime 9.511846\n",
      "Task (id #42) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_41.p output_41.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 119 MB, disk 990 MB, runtime 9.661101\n",
      "Task (id #43) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_42.p output_42.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 105 MB, disk 990 MB, runtime 10.321822\n",
      "Task (id #46) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_45.p output_45.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 107 MB, disk 990 MB, runtime 10.745252\n",
      "Task (id #45) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_44.p output_44.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 130 MB, disk 990 MB, runtime 11.202685\n",
      "Task (id #48) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_47.p output_47.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 1, memory: 142 MB, disk 990 MB, runtime 11.305455\n",
      "Task (id #23) complete: ./python_package_run --environment workqueue-coffea.tar.gz --unpack-to \"$WORK_QUEUE_SANDBOX\"/workqueue-coffea.tar.gz-env python fn_as_file function.p item_22.p output_22.p (return code 0)\n",
      "Output:\n",
      "\n",
      "allocated cores: 2, memory: 2000 MB, disk: 1000 MB\n",
      "measured cores: 2, memory: 135 MB, disk 990 MB, runtime 41.578128\n"
     ]
    }
   ],
   "source": [
    "wq_start = time()\n",
    "\n",
    "#run using work_queue executor\n",
    "output_work_queue = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=FancyDimuonProcessor(),\n",
    "                                  executor=work_queue_executor,\n",
    "                                  executor_args=executor_args,\n",
    "                                  chunksize=chunk_size\n",
    "                                 )\n",
    "\n",
    "wq_time = time() - wq_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on conda environments\n",
    "\n",
    "On each worker that is running tasks, we have to untar, unpack, and set up the conda environment so that we can run tasks from within that environment on the remote machine. This set-up process can take anywhere from 10 seconds to a few minutes to run. Only once that has completed on the worker can we begin to run tasks. Unfortunately, each task has to check whether the environment has already been set up (adding an extra few seconds to the runtime if the environment has already been set up on the worker). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up\n",
    "We started some workers on the Condor pool and we have to remove them once we are done to let other people make use of them :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All jobs of user \"ccarball\" have been marked for removal\r\n"
     ]
    }
   ],
   "source": [
    "!condor_rm ccarball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "speedup = iterative_time / wq_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterative Time:  172.90614676475525\n",
      "Work Queue Time:  329.9537396430969\n",
      "Speedup:  0.5240314807517675\n"
     ]
    }
   ],
   "source": [
    "print(\"Iterative Time: \", iterative_time)\n",
    "print(\"Work Queue Time: \", wq_time)\n",
    "print(\"Speedup: \", speedup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finishing Up\n",
    "Coffea plus WorkQueue is still relatively new and has a long way to go in terms of performance so stay tuned for more updates to come!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workqueue-coffea",
   "language": "python",
   "name": "workqueue-coffea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
